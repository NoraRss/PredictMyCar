# ğŸš— PredictMyCar

## Introduction

Estimer le prix dâ€™une voiture dâ€™occasion peut Ãªtre complexeâ€¯: plusieurs facteurs influencent sa valeur, comme lâ€™annÃ©e, le modÃ¨le, la puissance ou le kilomÃ©trage. Pour obtenir une estimation fiable, il est utile de se baser sur les donnÃ©es historiques du marchÃ©.

PredictMyCar est une application dÃ©veloppÃ©e en Python qui permet de gÃ©nÃ©rer cette estimation automatiquement. Lâ€™utilisateur saisit les caractÃ©ristiques dâ€™un vÃ©hicule et le modÃ¨le prÃ©dit le prix mÃ©dian observÃ© dans les annonces historiques. De plus, lâ€™application fournit un intervalle de prix pour reflÃ©ter la variation observÃ©e entre vÃ©hicules comparables, donnant ainsi une idÃ©e de la plage de prix rÃ©aliste pour ce profil de voiture.

Cette approche se base sur lâ€™analyse de milliers dâ€™annonces rÃ©elles collectÃ©es sur AutosphÃ¨re, permettant de proposer des estimations contextualisÃ©es et cohÃ©rentes avec le marchÃ© franÃ§ais des voitures dâ€™occasion.


## FonctionnalitÃ©s clÃ©s
- PrÃ©diction du prix des vÃ©hicules
Lâ€™utilisateur saisit les caractÃ©ristiques dâ€™une voiture Ã  l'aide de sliders et menus dÃ©roulants.
Lâ€™application fournit une estimation mÃ©diane du prix basÃ©e sur les donnÃ©es historiques.

- Intervalle de prixâ€¯: la plage affichÃ©e est calculÃ© Ã  partir de plusieurs entrÃ©es simulÃ©es dÃ©rivÃ©es du dataset, reprÃ©sentant de maniÃ¨re rÃ©aliste la variation des prix pour ce type de voiture.

- Visualisation des tendances du marchÃ©
Histogrammes et cartes interactives pour analyser les prix selon rÃ©gion, marque, type de carburant, etc...

- Exploration des donnÃ©es
PossibilitÃ© de filtrer par marque, modÃ¨le, annÃ©e, kilomÃ©trage, carburant ou puissance pour mieux comprendre le marchÃ©.


## Etapes du projetâ€¯:
- Scraping de donnÃ©es rÃ©elles pour obtenir des informations Ã  jour sur le marchÃ© de lâ€™occasion.

Nous avons rÃ©alisÃ© un scraping sur le site Autosphere, plusieurs fois, en rÃ©cupÃ©rant les donnÃ©es page par page (35 pages Ã  chaque fois, sachant quâ€™une page contient environ 23 annonces donc environ 800 annonces Ã  chaque fois), ce qui nous a permis dâ€™obtenir au total environ 5 600 annonces.

Nous avons scrapÃ©s pour chaque annonce les donnÃ©es suivantes : Marque, ModÃ¨le, Prix, AnnÃ©e, KilomÃ©trage, Puissance fiscale (CV), Puissance rÃ©elle (ch), Carburant, BoÃ®te de vitesse, Code postal

- Nettoyage et prÃ©traitement des donnÃ©es afin dâ€™avoir un jeu fiable et exploitable.
- PrÃ©diction du prix des vÃ©hicules via machine learning et sÃ©lection du modÃ¨le le plus performant.

Cette Ã©tape repose sur lâ€™entraÃ®nement et la comparaison de plusieurs modÃ¨les de rÃ©gression, notamment le Dummy Regressor, la rÃ©gression linÃ©aire, la rÃ©gression Lasso, lâ€™algorithme des k-plus proches voisins (KNN), lâ€™arbre de dÃ©cision, la forÃªt alÃ©atoire (Random Forest) et le Gradient Boosting.

Lâ€™Ã©valuation des performances est rÃ©alisÃ©e Ã  lâ€™aide dâ€™un prÃ©traitement des donnÃ©es et dâ€™une validation croisÃ©e, en sâ€™appuyant sur des mÃ©triques adaptÃ©es telles que lâ€™erreur absolue moyenne (MAE), la racine de lâ€™erreur quadratique moyenne (RMSE) et le coefficient de dÃ©termination (RÂ²). Le modÃ¨le final est sÃ©lectionnÃ© comme Ã©tant celui prÃ©sentant la plus faible erreur absolue moyenne (MAE) en validation croisÃ©e sur le jeu dâ€™entraÃ®nement. 

- CrÃ©ation d'une interface web interactive avec Streamlit pour rendre la prÃ©diction accessible Ã  tous.



## Mode dâ€™emploi
Lancer lâ€™application web : python -m streamlit run app.py


## Structure du projet
```
PredictMyCar/
â”œâ”€â”€ data/                     # Dossier pour les jeux de donnÃ©es
â”œâ”€â”€ ML/                       # Dossier pour les fichiers liÃ©s au Machine Learning
â”œâ”€â”€ tests/                    # Dossier pour les tests unitaires
â”‚ â”œâ”€â”€ test_autoscrap.py
â”‚ â”œâ”€â”€ test_data_preprocessing.py
â”‚ â””â”€â”€ test_model_training.py
â”œâ”€â”€ app.py                   # Application streamlit
â”œâ”€â”€ autoscrap_800.py         # Scraping des donnÃ©es (script des 35 premiÃ¨res pages, on changeait le nbr de pages Ã  scraper et le  nom du json en sortie pour les autres pages)
â”œâ”€â”€ data_fusion.py           # Fusion des donnÃ©es
â”œâ”€â”€ data_preprocessing.py    # PrÃ©paration et nettoyage des donnÃ©es
â”œâ”€â”€ model_training.py        # Machine Learning
â””â”€â”€ README.md
```                  


## Technologies utilisÃ©es
Logiciel : Python 3.13.9

BibliothÃ¨ques :
- Scraping : Playwright 
- Nettoyage et prÃ©traitement : Pandas, NumPy, Regex
- Visualisation : Matplotlib, Seaborn, Plotly
- Machine Learning : Scikit-learn (Linear Regression, Random Forest, Gradient Boostingâ€¦)
- Application web : Streamlit


## Auteurs 
Rousseau Nora

Boudamous Lyna











